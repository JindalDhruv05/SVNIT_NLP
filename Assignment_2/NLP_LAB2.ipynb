{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install automathon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FioRpYPF5gQJ",
        "outputId": "1ed66044-f018-42b5-f303-4f6b33890286"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting automathon\n",
            "  Downloading automathon-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting graphviz==0.16 (from automathon)\n",
            "  Downloading graphviz-0.16-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Downloading automathon-0.0.15-py3-none-any.whl (13 kB)\n",
            "Downloading graphviz-0.16-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: graphviz, automathon\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.21\n",
            "    Uninstalling graphviz-0.21:\n",
            "      Successfully uninstalled graphviz-0.21\n",
            "Successfully installed automathon-0.0.15 graphviz-0.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install automathon first: pip install automathon\n",
        "\n",
        "from automathon import DFA\n",
        "\n",
        "# DFA definition\n",
        "# States: q0 (start), q1 (valid), q_dead (invalid)\n",
        "# Alphabet: lowercase letters a-z\n",
        "# Transitions:\n",
        "#   q0 --lowercase--> q1\n",
        "#   q1 --lowercase--> q1\n",
        "# Any other input -> q_dead\n",
        "\n",
        "states = {'q0', 'q1'}\n",
        "input_symbols = set('abcdefghijklmnopqrstuvwxyz')\n",
        "transitions = {\n",
        "    'q0': {ch: 'q1' for ch in input_symbols},\n",
        "    'q1': {ch: 'q1' for ch in input_symbols}\n",
        "}\n",
        "\n",
        "# Start and final states\n",
        "initial_state = 'q0'\n",
        "final_states = {'q1'}\n",
        "\n",
        "# Create DFA\n",
        "dfa = DFA(states, input_symbols, transitions, initial_state, final_states)\n",
        "\n",
        "# Function to check a word\n",
        "def check_word(word):\n",
        "    # First, reject if any char not lowercase a-z\n",
        "    if not word or any(ch not in input_symbols for ch in word):\n",
        "        return \"Not Accepted\"\n",
        "    # Process in DFA\n",
        "    if dfa.accept(word):\n",
        "        return \"Accepted\"\n",
        "    return \"Not Accepted\"\n",
        "\n",
        "# Test cases\n",
        "words = [\"cat\", \"dog\", \"a\", \"zebra\", \"dog1\", \"1dog\", \"DogHouse\", \"Dog_house\", \" cats\"]\n",
        "for w in words:\n",
        "    print(f\"{w!r} -> {check_word(w)}\")\n",
        "\n",
        "# Visualization\n",
        "dfa.view(\"dfa_diagram.png\")  # Saves DFA diagram as PNG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aE_CPGI5dmq",
        "outputId": "b36dcd42-9a29-4b7f-a852-53aead9921a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'cat' -> Accepted\n",
            "'dog' -> Accepted\n",
            "'a' -> Accepted\n",
            "'zebra' -> Accepted\n",
            "'dog1' -> Not Accepted\n",
            "'1dog' -> Not Accepted\n",
            "'DogHouse' -> Not Accepted\n",
            "'Dog_house' -> Not Accepted\n",
            "' cats' -> Not Accepted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "# Load all nouns from the brown_nouns.txt file\n",
        "with open(\"/content/brown_nouns.txt\") as f:\n",
        "    nouns = [w.strip() for w in f if w.strip()]\n",
        "\n",
        "# Utility function: check if letter is vowel\n",
        "def is_vowel(ch):\n",
        "    return ch in \"aeiou\"\n",
        "\n",
        "# FST simulation\n",
        "def analyze_word(word):\n",
        "    # Reject if contains characters outside lowercase letters\n",
        "    if not word.isalpha() or not word.islower():\n",
        "        return \"Invalid Word\"\n",
        "\n",
        "    # Singular: no plural suffix\n",
        "    if not word.endswith('s'):\n",
        "        return f\"{word}+N+SG\"\n",
        "\n",
        "    # Plural candidates:\n",
        "    if word.endswith(\"ies\"):\n",
        "        # Rule: Y replacement: consonant + y -> ies\n",
        "        if len(word) >= 4 and not is_vowel(word[-4]):\n",
        "            root = word[:-3] + \"y\"\n",
        "            return f\"{root}+N+PL\"\n",
        "        else:\n",
        "            return \"Invalid Word\"\n",
        "\n",
        "    elif word.endswith(\"es\"):\n",
        "        # Rule: E insertion: after s, z, x, ch, sh\n",
        "        root = word[:-2]\n",
        "        if root.endswith((\"s\", \"x\", \"z\", \"ch\", \"sh\")):\n",
        "            return f\"{root}+N+PL\"\n",
        "        else:\n",
        "            return \"Invalid Word\"\n",
        "\n",
        "    else:\n",
        "        # Rule: Simple S addition\n",
        "        root = word[:-1]\n",
        "        # Reject if it should have used 'es' or 'ies'\n",
        "        if root.endswith((\"s\", \"x\", \"z\", \"ch\", \"sh\")):\n",
        "            return \"Invalid Word\"\n",
        "        if len(root) >= 2 and root.endswith(\"y\") and not is_vowel(root[-2]):\n",
        "            return \"Invalid Word\"\n",
        "        return f\"{root}+N+PL\"\n",
        "\n",
        "# Test with given examples\n",
        "examples = [\"cat\", \"dog\", \"a\", \"zebra\", \"foxes\", \"fox\", \"foxs\",\n",
        "            \"tries\", \"try\", \"trys\", \"toies\", \"bags\"]\n",
        "\n",
        "for w in examples:\n",
        "    print(f\"{w} -> {analyze_word(w)}\")\n",
        "\n",
        "# Process all nouns from the corpus\n",
        "results = {w: analyze_word(w) for w in nouns}\n",
        "\n",
        "# Save output for inspection\n",
        "with open(\"noun_analysis.txt\", \"w\") as f:\n",
        "    for w, analysis in results.items():\n",
        "        f.write(f\"{w} = {analysis}\\n\")\n",
        "\n",
        "print(\"\\nAnalysis complete. Results saved to noun_analysis.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3Ve1zQv7Pjl",
        "outputId": "12a553c3-34cc-4fbd-e61d-2556bd7136be"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat -> cat+N+SG\n",
            "dog -> dog+N+SG\n",
            "a -> a+N+SG\n",
            "zebra -> zebra+N+SG\n",
            "foxes -> fox+N+PL\n",
            "fox -> fox+N+SG\n",
            "foxs -> Invalid Word\n",
            "tries -> try+N+PL\n",
            "try -> try+N+SG\n",
            "trys -> Invalid Word\n",
            "toies -> Invalid Word\n",
            "bags -> bag+N+PL\n",
            "\n",
            "Analysis complete. Results saved to noun_analysis.txt\n"
          ]
        }
      ]
    }
  ]
}