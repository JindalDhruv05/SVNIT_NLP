{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install automathon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FioRpYPF5gQJ",
        "outputId": "1ed66044-f018-42b5-f303-4f6b33890286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting automathon\n",
            "  Downloading automathon-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting graphviz==0.16 (from automathon)\n",
            "  Downloading graphviz-0.16-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Downloading automathon-0.0.15-py3-none-any.whl (13 kB)\n",
            "Downloading graphviz-0.16-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: graphviz, automathon\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.21\n",
            "    Uninstalling graphviz-0.21:\n",
            "      Successfully uninstalled graphviz-0.21\n",
            "Successfully installed automathon-0.0.15 graphviz-0.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install automathon first: pip install automathon\n",
        "\n",
        "from automathon import DFA\n",
        "\n",
        "# DFA definition\n",
        "# States: q0 (start), q1 (valid), q_dead (invalid)\n",
        "# Alphabet: lowercase letters a-z\n",
        "# Transitions:\n",
        "#   q0 --lowercase--> q1\n",
        "#   q1 --lowercase--> q1\n",
        "# Any other input -> q_dead\n",
        "\n",
        "states = {'q0', 'q1'}\n",
        "input_symbols = set('abcdefghijklmnopqrstuvwxyz')\n",
        "transitions = {\n",
        "    'q0': {ch: 'q1' for ch in input_symbols},\n",
        "    'q1': {ch: 'q1' for ch in input_symbols}\n",
        "}\n",
        "\n",
        "# Start and final states\n",
        "initial_state = 'q0'\n",
        "final_states = {'q1'}\n",
        "\n",
        "# Create DFA\n",
        "dfa = DFA(states, input_symbols, transitions, initial_state, final_states)\n",
        "\n",
        "# Function to check a word\n",
        "def check_word(word):\n",
        "    # First, reject if any char not lowercase a-z\n",
        "    if not word or any(ch not in input_symbols for ch in word):\n",
        "        return \"Not Accepted\"\n",
        "    # Process in DFA\n",
        "    if dfa.accept(word):\n",
        "        return \"Accepted\"\n",
        "    return \"Not Accepted\"\n",
        "\n",
        "# Test cases\n",
        "words = [\"cat\", \"dog\", \"a\", \"zebra\", \"dog1\", \"1dog\", \"DogHouse\", \"Dog_house\", \" cats\"]\n",
        "for w in words:\n",
        "    print(f\"{w!r} -> {check_word(w)}\")\n",
        "\n",
        "# Visualization\n",
        "dfa.view(\"dfa_diagram.png\")  # Saves DFA diagram as PNG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aE_CPGI5dmq",
        "outputId": "b36dcd42-9a29-4b7f-a852-53aead9921a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'cat' -> Accepted\n",
            "'dog' -> Accepted\n",
            "'a' -> Accepted\n",
            "'zebra' -> Accepted\n",
            "'dog1' -> Not Accepted\n",
            "'1dog' -> Not Accepted\n",
            "'DogHouse' -> Not Accepted\n",
            "'Dog_house' -> Not Accepted\n",
            "' cats' -> Not Accepted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MorphologicalFST:\n",
        "    def __init__(self):\n",
        "        self.states = {\n",
        "            'START',\n",
        "            'ROOT',\n",
        "            'S_END',\n",
        "            'Z_END',\n",
        "            'X_END',\n",
        "            'CH_END',\n",
        "            'SH_END',\n",
        "            'Y_END',\n",
        "            'ACCEPT',\n",
        "            'REJECT'\n",
        "        }\n",
        "\n",
        "        self.irregular_patterns = {\n",
        "            'children': 'child',\n",
        "            'feet': 'foot',\n",
        "            'teeth': 'tooth',\n",
        "            'men': 'man',\n",
        "            'women': 'woman',\n",
        "            'mice': 'mouse',\n",
        "            'geese': 'goose',\n",
        "            'people': 'person'\n",
        "        }\n",
        "\n",
        "        self.non_plural_es_words = {\n",
        "            'analyses', 'bases', 'crises', 'diagnoses', 'hypotheses',\n",
        "            'oases', 'parentheses', 'syntheses', 'theses'\n",
        "        }\n",
        "\n",
        "    def analyze_word(self, word):\n",
        "        if not word or not word.isalpha():\n",
        "            return f\"{word}: Invalid Word\"\n",
        "\n",
        "        word = word.lower().strip()\n",
        "\n",
        "        if word in self.irregular_patterns:\n",
        "            root = self.irregular_patterns[word]\n",
        "            return f\"{word} = {root}+N+PL\"\n",
        "\n",
        "        analysis = self.analyze_plural_morphology(word)\n",
        "\n",
        "        if analysis:\n",
        "            return analysis\n",
        "        else:\n",
        "            return f\"{word} = {word}+N+SG\"\n",
        "\n",
        "    def analyze_plural_morphology(self, word):\n",
        "        if word.endswith('es') and len(word) > 2:\n",
        "            if word in self.non_plural_es_words:\n",
        "                return None\n",
        "\n",
        "            root_candidate = word[:-2]\n",
        "\n",
        "            if (root_candidate.endswith(('s', 'x', 'z')) or root_candidate.endswith(('ch', 'sh'))):\n",
        "                return f\"{word} = {root_candidate}+N+PL\"\n",
        "\n",
        "        if word.endswith('ies') and len(word)>3:\n",
        "            root_candidate = word[:-3] + 'y'\n",
        "            if not word.endswith('eies'):\n",
        "                return f\"{word} = {root_candidate}+N+PL\"\n",
        "\n",
        "        if word.endswith('s') and len(word) > 1:\n",
        "            if not word.endswith(('es', 'ies')):\n",
        "                root_candidate = word[:-1]\n",
        "\n",
        "                if not self.is_naturally_s_ending(root_candidate, word):\n",
        "                    return f\"{word} = {root_candidate}+N+PL\"\n",
        "\n",
        "        return None\n",
        "\n",
        "    def is_naturally_s_ending(self, root, word):\n",
        "        naturally_s_ending = [\n",
        "            'lens', 'bus', 'gas', 'glass', 'class', 'mass', 'pass', 'bass',\n",
        "            'grass', 'dress', 'stress', 'press', 'chess', 'mess', 'less',\n",
        "            'business', 'princess', 'process', 'success', 'access', 'address'\n",
        "        ]\n",
        "\n",
        "        if word in naturally_s_ending:\n",
        "            return True\n",
        "\n",
        "        if len(root) < 2:\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def process_corpus(self, filename):\n",
        "        analyses = []\n",
        "        try:\n",
        "            with open(filename, 'r', encoding='utf-8') as file:\n",
        "                for line in file:\n",
        "                    words = line.strip().split()\n",
        "                    for word in words:\n",
        "                        clean_word = ''.join(c for c in word if c.isalpha())\n",
        "                        if clean_word:\n",
        "                            analysis = self.analyze_word(clean_word)\n",
        "                            analyses.append(analysis)\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: File '{filename}' not found.\")\n",
        "            return []\n",
        "\n",
        "        return analyses\n",
        "\n",
        "def main():\n",
        "    fst = MorphologicalFST()\n",
        "    test_words = [\n",
        "        # Rule 1: E insertion\n",
        "        'foxes',      # fox + es\n",
        "        'watches',    # watch + es\n",
        "        'boxes',      # box + es\n",
        "        'glasses',    # glass + es\n",
        "        'wishes',     # wish + es\n",
        "\n",
        "        # Rule 2: Y replacement\n",
        "        'tries',      # try -> tries\n",
        "        'flies',      # fly -> flies\n",
        "        'babies',     # baby -> babies\n",
        "        'cities',     # city -> cities\n",
        "\n",
        "        # Rule 3: S addition\n",
        "        'bags',       # bag + s\n",
        "        'cats',       # cat + s\n",
        "        'dogs',       # dog + s\n",
        "        'books',      # book + s\n",
        "\n",
        "        # Singular words\n",
        "        'investigation',\n",
        "        'primary',\n",
        "        'election',\n",
        "        'evidence',\n",
        "        'jury',\n",
        "        'manner',\n",
        "\n",
        "        # Edge cases\n",
        "        'fox',        # Should be singular\n",
        "        'lens',       # Naturally ends in s\n",
        "        'bus',        # Naturally ends in s\n",
        "\n",
        "        # Invalid cases\n",
        "        'foxs',       # Invalid plural\n",
        "    ]\n",
        "\n",
        "    for word in test_words:\n",
        "        analysis=fst.analyze_word(word)\n",
        "        print(analysis)\n",
        "\n",
        "    analyses = fst.process_corpus(\"brown_nouns.txt\")\n",
        "\n",
        "    with open(\"output.txt\", \"w\", encoding='utf-8') as f:\n",
        "        for a in analyses:\n",
        "            f.write(a+\"\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvdVaFvalaeW",
        "outputId": "028a1178-0d34-4d28-8b3b-fb6b440cd179"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "foxes = fox+N+PL\n",
            "watches = watch+N+PL\n",
            "boxes = box+N+PL\n",
            "glasses = glass+N+PL\n",
            "wishes = wish+N+PL\n",
            "tries = try+N+PL\n",
            "flies = fly+N+PL\n",
            "babies = baby+N+PL\n",
            "cities = city+N+PL\n",
            "bags = bag+N+PL\n",
            "cats = cat+N+PL\n",
            "dogs = dog+N+PL\n",
            "books = book+N+PL\n",
            "investigation = investigation+N+SG\n",
            "primary = primary+N+SG\n",
            "election = election+N+SG\n",
            "evidence = evidence+N+SG\n",
            "jury = jury+N+SG\n",
            "manner = manner+N+SG\n",
            "fox = fox+N+SG\n",
            "lens = lens+N+SG\n",
            "bus = bus+N+SG\n",
            "foxs = fox+N+PL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "# Load all nouns from the brown_nouns.txt file\n",
        "with open(\"/content/brown_nouns.txt\") as f:\n",
        "    nouns = [w.strip() for w in f if w.strip()]\n",
        "\n",
        "# Utility function: check if letter is vowel\n",
        "def is_vowel(ch):\n",
        "    return ch in \"aeiou\"\n",
        "\n",
        "# FST simulation\n",
        "def analyze_word(word):\n",
        "    # Reject if contains characters outside lowercase letters\n",
        "    if not word.isalpha() or not word.islower():\n",
        "        return \"Invalid Word\"\n",
        "\n",
        "    # Singular: no plural suffix\n",
        "    if not word.endswith('s'):\n",
        "        return f\"{word}+N+SG\"\n",
        "\n",
        "    # Plural candidates:\n",
        "    if word.endswith(\"ies\"):\n",
        "        # Rule: Y replacement: consonant + y -> ies\n",
        "        if len(word) >= 4 and not is_vowel(word[-4]):\n",
        "            root = word[:-3] + \"y\"\n",
        "            return f\"{root}+N+PL\"\n",
        "        else:\n",
        "            return \"Invalid Word\"\n",
        "\n",
        "    elif word.endswith(\"es\"):\n",
        "        # Rule: E insertion: after s, z, x, ch, sh\n",
        "        root = word[:-2]\n",
        "        if root.endswith((\"s\", \"x\", \"z\", \"ch\", \"sh\")):\n",
        "            return f\"{root}+N+PL\"\n",
        "        else:\n",
        "            return \"Invalid Word\"\n",
        "\n",
        "    else:\n",
        "        # Rule: Simple S addition\n",
        "        root = word[:-1]\n",
        "        # Reject if it should have used 'es' or 'ies'\n",
        "        if root.endswith((\"s\", \"x\", \"z\", \"ch\", \"sh\")):\n",
        "            return \"Invalid Word\"\n",
        "        if len(root) >= 2 and root.endswith(\"y\") and not is_vowel(root[-2]):\n",
        "            return \"Invalid Word\"\n",
        "        return f\"{root}+N+PL\"\n",
        "\n",
        "# Test with given examples\n",
        "examples = [\"cat\", \"dog\", \"a\", \"zebra\", \"foxes\", \"fox\", \"foxs\",\n",
        "            \"tries\", \"try\", \"trys\", \"toies\", \"bags\"]\n",
        "\n",
        "for w in examples:\n",
        "    print(f\"{w} -> {analyze_word(w)}\")\n",
        "\n",
        "# Process all nouns from the corpus\n",
        "results = {w: analyze_word(w) for w in nouns}\n",
        "\n",
        "# Save output for inspection\n",
        "with open(\"noun_analysis.txt\", \"w\") as f:\n",
        "    for w, analysis in results.items():\n",
        "        f.write(f\"{w} = {analysis}\\n\")\n",
        "\n",
        "print(\"\\nAnalysis complete. Results saved to noun_analysis.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3AUvCtCjLfA",
        "outputId": "93787d23-8da0-4214-87be-3291891d0425"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat -> cat+N+SG\n",
            "dog -> dog+N+SG\n",
            "a -> a+N+SG\n",
            "zebra -> zebra+N+SG\n",
            "foxes -> fox+N+PL\n",
            "fox -> fox+N+SG\n",
            "foxs -> Invalid Word\n",
            "tries -> try+N+PL\n",
            "try -> try+N+SG\n",
            "trys -> Invalid Word\n",
            "toies -> Invalid Word\n",
            "bags -> bag+N+PL\n",
            "\n",
            "Analysis complete. Results saved to noun_analysis.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "# Create Graphviz Digraph\n",
        "fst = Digraph(\"PluralFST\", format=\"png\")\n",
        "fst.attr(rankdir=\"LR\", size=\"8\")\n",
        "\n",
        "# States\n",
        "states = [\"q0\", \"q_s\", \"q_es\", \"q_ies\", \"q_root_SG\", \"q_root_PL\", \"q_invalid\"]\n",
        "accept_states = [\"q_root_SG\", \"q_root_PL\"]\n",
        "\n",
        "for s in states:\n",
        "    if s in accept_states:\n",
        "        fst.attr(\"node\", shape=\"doublecircle\", style=\"filled\", fillcolor=\"lightgreen\")\n",
        "    elif s == \"q_invalid\":\n",
        "        fst.attr(\"node\", shape=\"doublecircle\", style=\"filled\", fillcolor=\"red\")\n",
        "    else:\n",
        "        fst.attr(\"node\", shape=\"circle\", style=\"filled\", fillcolor=\"lightblue\")\n",
        "    fst.node(s)\n",
        "\n",
        "# Transitions\n",
        "# Start transitions\n",
        "fst.edge(\"q0\", \"q_s\", label=\"s\")\n",
        "fst.edge(\"q0\", \"q_root_SG\", label=\"a..z except s / emit root+N+SG\")\n",
        "\n",
        "# q_s transitions\n",
        "fst.edge(\"q_s\", \"q_es\", label=\"e\")\n",
        "fst.edge(\"q_s\", \"q_root_PL\", label=\"letter not requiring es or ies / emit root+N+PL\")\n",
        "fst.edge(\"q_s\", \"q_invalid\", label=\"x,z,s,ch,sh or y preceded by consonant\")\n",
        "\n",
        "# q_es transitions\n",
        "fst.edge(\"q_es\", \"q_ies\", label=\"i\")\n",
        "fst.edge(\"q_es\", \"q_root_PL\", label=\"x,z,s,ch,sh / emit root+N+PL\")\n",
        "fst.edge(\"q_es\", \"q_invalid\", label=\"otherwise\")\n",
        "\n",
        "# q_ies transitions\n",
        "fst.edge(\"q_ies\", \"q_root_PL\", label=\"consonant / root ends with y\")\n",
        "fst.edge(\"q_ies\", \"q_invalid\", label=\"vowel before y\")\n",
        "\n",
        "# Root processing loops\n",
        "fst.edge(\"q_root_SG\", \"q_root_SG\", label=\"a..z / accumulate root\")\n",
        "fst.edge(\"q_root_PL\", \"q_root_PL\", label=\"a..z / accumulate root\")\n",
        "\n",
        "# Invalid loops\n",
        "fst.edge(\"q_invalid\", \"q_invalid\", label=\"a..z\")\n",
        "\n",
        "# Save and render to file in /mnt/data\n",
        "output_path = \"plural_fst\"\n",
        "fst.render(output_path, cleanup=True)\n",
        "print(f\"FST diagram saved to {output_path}.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1f7Qi87o_QL",
        "outputId": "8f6fbd2a-6bb1-4541-d1e6-4e1dd2fb174d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FST diagram saved to plural_fst.png\n"
          ]
        }
      ]
    }
  ]
}