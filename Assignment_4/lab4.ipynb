{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa24861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import re\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137968cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in dataset: 141536\n",
      "First 5 sentences:\n",
      "1: लोगों को बिलों संबंधी सुविधा देना ही उनका काम\n",
      "2: इनेलो 1987 में उस वक्त ऐसे ही दोराहे पर खड़ी थी , जब पूर्व उपप्रधानमंत्री देवीलाल ने अपने पुत्र ओमप्रकाश चौटाला को अपना राजनीतिक उत्तराधिकारी घोषित किया था।\n",
      "3: हालांकि तब पार्टी पर देवीलाल की मजबूत पकड़ के चलते पार्टी टूटने से बच गई थी।\n",
      "4: 1989 में देवीलाल केन्द्र की राजनीति में सक्रिय हो गए थे और उनके उपप्रधानमंत्री बनने के पश्चात् उनके तीन बेटों जगदीश सिंह , रणजीत सिंह और ओमप्रकाश चौटाला में से रणजीत और ओमप्रकाश के बीच हरियाणा में उनकी राजनीतिक विरासत को लेकर जंग शुरू हो गई थी।\n",
      "5: उन परिस्थितियों में देवीलाल ने कड़ा निर्णय लेते हुए पार्टी की बागडोर ओमप्रकाश चौटाला के हवाले कर दी थी , जिसके बाद रणजीत की बगावत का असर पार्टी , संगठन और उनकी सरकार पर भी पड़ा था।\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenized Hindi data\n",
    "with open('tokenized_hi.txt', 'r', encoding='utf-8') as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "# Remove newline characters and filter out empty sentences\n",
    "sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "print(f\"Total sentences in dataset: {len(sentences)}\")\n",
    "print(f\"First 5 sentences:\")\n",
    "for i in range(5):\n",
    "    print(f\"{i+1}: {sentences[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a0325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "    def __init__(self, n):\n",
    "        self.n = n  # n-gram size\n",
    "        self.ngrams = defaultdict(int)\n",
    "        self.context_counts = defaultdict(int)\n",
    "        self.vocabulary = set()\n",
    "        \n",
    "    def preprocess_sentence(self, sentence):\n",
    "        \"\"\"Add start and end tokens to sentence\"\"\"\n",
    "        tokens = sentence.split()\n",
    "        if self.n > 1:\n",
    "            # Add start tokens\n",
    "            padded_tokens = ['<s>'] * (self.n - 1) + tokens + ['</s>']\n",
    "        else:\n",
    "            padded_tokens = tokens + ['</s>']\n",
    "        return padded_tokens\n",
    "    \n",
    "    def train(self, sentences):\n",
    "        \"\"\"Train the language model on sentences\"\"\"\n",
    "        for sentence in sentences:\n",
    "            tokens = self.preprocess_sentence(sentence)\n",
    "            self.vocabulary.update(tokens)\n",
    "            \n",
    "            # Generate n-grams\n",
    "            for i in range(len(tokens) - self.n + 1):\n",
    "                ngram = tuple(tokens[i:i + self.n])\n",
    "                self.ngrams[ngram] += 1\n",
    "                \n",
    "                # For context counts (n-1 grams)\n",
    "                if self.n > 1:\n",
    "                    context = ngram[:-1]\n",
    "                    self.context_counts[context] += 1\n",
    "                else:\n",
    "                    # For unigram, context is total count\n",
    "                    self.context_counts[('',)] += 1\n",
    "    \n",
    "    def get_probability(self, ngram):\n",
    "        \"\"\"Get probability of n-gram\"\"\"\n",
    "        if self.n == 1:\n",
    "            total_count = sum(self.ngrams.values())\n",
    "            return self.ngrams[ngram] / total_count if total_count > 0 else 0\n",
    "        else:\n",
    "            context = ngram[:-1]\n",
    "            context_count = self.context_counts[context]\n",
    "            return self.ngrams[ngram] / context_count if context_count > 0 else 0\n",
    "    \n",
    "    def sentence_probability(self, sentence):\n",
    "        \"\"\"Calculate probability of a sentence\"\"\"\n",
    "        tokens = self.preprocess_sentence(sentence)\n",
    "        prob = 1.0\n",
    "        \n",
    "        for i in range(len(tokens) - self.n + 1):\n",
    "            ngram = tuple(tokens[i:i + self.n])\n",
    "            ngram_prob = self.get_probability(ngram)\n",
    "            if ngram_prob == 0:\n",
    "                return 0  # If any n-gram has zero probability\n",
    "            prob *= ngram_prob\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    def sentence_log_probability(self, sentence):\n",
    "        \"\"\"Calculate log probability of a sentence to avoid underflow\"\"\"\n",
    "        tokens = self.preprocess_sentence(sentence)\n",
    "        log_prob = 0.0\n",
    "        \n",
    "        for i in range(len(tokens) - self.n + 1):\n",
    "            ngram = tuple(tokens[i:i + self.n])\n",
    "            ngram_prob = self.get_probability(ngram)\n",
    "            if ngram_prob == 0:\n",
    "                return float('-inf')  # Log of zero is negative infinity\n",
    "            log_prob += log(ngram_prob)\n",
    "        \n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0851099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothedLanguageModel(LanguageModel):\n",
    "    def __init__(self, n, smoothing_type='add_one', k=1):\n",
    "        super().__init__(n)\n",
    "        self.smoothing_type = smoothing_type\n",
    "        self.k = k  # For add-k smoothing\n",
    "        \n",
    "    def get_smoothed_probability(self, ngram):\n",
    "        \"\"\"Get smoothed probability of n-gram\"\"\"\n",
    "        if self.smoothing_type == 'add_one':\n",
    "            return self._add_one_smoothing(ngram)\n",
    "        elif self.smoothing_type == 'add_k':\n",
    "            return self._add_k_smoothing(ngram)\n",
    "        elif self.smoothing_type == 'add_token_type':\n",
    "            return self._add_token_type_smoothing(ngram)\n",
    "        else:\n",
    "            return self.get_probability(ngram)\n",
    "    \n",
    "    def _add_one_smoothing(self, ngram):\n",
    "        \"\"\"Add-one (Laplace) smoothing\"\"\"\n",
    "        if self.n == 1:\n",
    "            total_count = sum(self.ngrams.values())\n",
    "            vocab_size = len(self.vocabulary)\n",
    "            return (self.ngrams[ngram] + 1) / (total_count + vocab_size)\n",
    "        else:\n",
    "            context = ngram[:-1]\n",
    "            context_count = self.context_counts[context]\n",
    "            vocab_size = len(self.vocabulary)\n",
    "            return (self.ngrams[ngram] + 1) / (context_count + vocab_size)\n",
    "    \n",
    "    def _add_k_smoothing(self, ngram):\n",
    "        \"\"\"Add-k smoothing\"\"\"\n",
    "        if self.n == 1:\n",
    "            total_count = sum(self.ngrams.values())\n",
    "            vocab_size = len(self.vocabulary)\n",
    "            return (self.ngrams[ngram] + self.k) / (total_count + self.k * vocab_size)\n",
    "        else:\n",
    "            context = ngram[:-1]\n",
    "            context_count = self.context_counts[context]\n",
    "            vocab_size = len(self.vocabulary)\n",
    "            return (self.ngrams[ngram] + self.k) / (context_count + self.k * vocab_size)\n",
    "    \n",
    "    def _add_token_type_smoothing(self, ngram):\n",
    "        \"\"\"Add token type smoothing (may not be a probability distribution)\"\"\"\n",
    "        if self.n == 1:\n",
    "            total_count = sum(self.ngrams.values())\n",
    "            vocab_size = len(self.vocabulary)\n",
    "            # Add the number of unique token types in vocabulary\n",
    "            return (self.ngrams[ngram] + vocab_size) / (total_count + vocab_size * vocab_size)\n",
    "        else:\n",
    "            context = ngram[:-1]\n",
    "            context_count = self.context_counts[context]\n",
    "            vocab_size = len(self.vocabulary)\n",
    "            return (self.ngrams[ngram] + vocab_size) / (context_count + vocab_size * vocab_size)\n",
    "    \n",
    "    def sentence_smoothed_probability(self, sentence):\n",
    "        \"\"\"Calculate smoothed probability of a sentence\"\"\"\n",
    "        tokens = self.preprocess_sentence(sentence)\n",
    "        prob = 1.0\n",
    "        \n",
    "        for i in range(len(tokens) - self.n + 1):\n",
    "            ngram = tuple(tokens[i:i + self.n])\n",
    "            ngram_prob = self.get_smoothed_probability(ngram)\n",
    "            prob *= ngram_prob\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    def sentence_smoothed_log_probability(self, sentence):\n",
    "        \"\"\"Calculate smoothed log probability of a sentence\"\"\"\n",
    "        tokens = self.preprocess_sentence(sentence)\n",
    "        log_prob = 0.0\n",
    "        \n",
    "        for i in range(len(tokens) - self.n + 1):\n",
    "            ngram = tuple(tokens[i:i + self.n])\n",
    "            ngram_prob = self.get_smoothed_probability(ngram)\n",
    "            if ngram_prob > 0:\n",
    "                log_prob += log(ngram_prob)\n",
    "            else:\n",
    "                return float('-inf')\n",
    "        \n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "826ff2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training language models...\n",
      "Unigram model: 103893 unique unigrams\n",
      "Bigram model: 939355 unique bigrams\n",
      "Trigram model: 2063410 unique trigrams\n",
      "Quadrigram model: 2649242 unique quadrigrams\n",
      "Vocabulary size: 103893\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Create and train all four language models\n",
    "print(\"Training language models...\")\n",
    "\n",
    "# 1. Unigram Model\n",
    "unigram_model = LanguageModel(n=1)\n",
    "unigram_model.train(sentences)\n",
    "print(f\"Unigram model: {len(unigram_model.ngrams)} unique unigrams\")\n",
    "\n",
    "# 2. Bigram Model\n",
    "bigram_model = LanguageModel(n=2)\n",
    "bigram_model.train(sentences)\n",
    "print(f\"Bigram model: {len(bigram_model.ngrams)} unique bigrams\")\n",
    "\n",
    "# 3. Trigram Model\n",
    "trigram_model = LanguageModel(n=3)\n",
    "trigram_model.train(sentences)\n",
    "print(f\"Trigram model: {len(trigram_model.ngrams)} unique trigrams\")\n",
    "\n",
    "# 4. Quadrigram Model\n",
    "quadrigram_model = LanguageModel(n=4)\n",
    "quadrigram_model.train(sentences)\n",
    "print(f\"Quadrigram model: {len(quadrigram_model.ngrams)} unique quadrigrams\")\n",
    "\n",
    "print(f\"Vocabulary size: {len(unigram_model.vocabulary)}\")\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04cce22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating smoothed language models...\n",
      "Smoothed models created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create smoothed models for each n-gram type\n",
    "print(\"Creating smoothed language models...\")\n",
    "\n",
    "# Smoothed Unigram Models\n",
    "unigram_add_one = SmoothedLanguageModel(n=1, smoothing_type='add_one')\n",
    "unigram_add_one.train(sentences)\n",
    "\n",
    "unigram_add_k = SmoothedLanguageModel(n=1, smoothing_type='add_k', k=0.5)\n",
    "unigram_add_k.train(sentences)\n",
    "\n",
    "unigram_add_token = SmoothedLanguageModel(n=1, smoothing_type='add_token_type')\n",
    "unigram_add_token.train(sentences)\n",
    "\n",
    "# Smoothed Bigram Models\n",
    "bigram_add_one = SmoothedLanguageModel(n=2, smoothing_type='add_one')\n",
    "bigram_add_one.train(sentences)\n",
    "\n",
    "bigram_add_k = SmoothedLanguageModel(n=2, smoothing_type='add_k', k=0.5)\n",
    "bigram_add_k.train(sentences)\n",
    "\n",
    "bigram_add_token = SmoothedLanguageModel(n=2, smoothing_type='add_token_type')\n",
    "bigram_add_token.train(sentences)\n",
    "\n",
    "# Smoothed Trigram Models\n",
    "trigram_add_one = SmoothedLanguageModel(n=3, smoothing_type='add_one')\n",
    "trigram_add_one.train(sentences)\n",
    "\n",
    "trigram_add_k = SmoothedLanguageModel(n=3, smoothing_type='add_k', k=0.5)\n",
    "trigram_add_k.train(sentences)\n",
    "\n",
    "trigram_add_token = SmoothedLanguageModel(n=3, smoothing_type='add_token_type')\n",
    "trigram_add_token.train(sentences)\n",
    "\n",
    "# Smoothed Quadrigram Models\n",
    "quadrigram_add_one = SmoothedLanguageModel(n=4, smoothing_type='add_one')\n",
    "quadrigram_add_one.train(sentences)\n",
    "\n",
    "quadrigram_add_k = SmoothedLanguageModel(n=4, smoothing_type='add_k', k=0.5)\n",
    "quadrigram_add_k.train(sentences)\n",
    "\n",
    "quadrigram_add_token = SmoothedLanguageModel(n=4, smoothing_type='add_token_type')\n",
    "quadrigram_add_token.train(sentences)\n",
    "\n",
    "print(\"Smoothed models created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d96cb1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 1000 sentences for testing\n",
      "Sample test sentences:\n",
      "1: रालोसपा के प्रदेश अध्यक्ष भूदेव चौधरी के पाला बदलकर राजद में सोमवार को शामिल होने के बारे में पूछे जाने पर कुशवाहा ने कहा कि मैंने दूसरे किनारे तक पहुंचने के इरादे से समुद्र में अपनी नाव डाली है पर बीच में छोड़कर जो जाना चाहते हैं तो उनका स्वागत है।\n",
      "2: नए नियम के फायदे\n",
      "3: अगर राहुल कंवल सवालों का जवाब हमें देते हैं तो इस खबर को उनके पक्ष के साथ अपडेट किया जाएगा।\n"
     ]
    }
   ],
   "source": [
    "# Select 1000 random sentences for testing\n",
    "random.seed(42)  # For reproducibility\n",
    "test_sentences = random.sample(sentences, min(1000, len(sentences)))\n",
    "print(f\"Selected {len(test_sentences)} sentences for testing\")\n",
    "print(\"Sample test sentences:\")\n",
    "for i in range(3):\n",
    "    print(f\"{i+1}: {test_sentences[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad5f2367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating all models on test sentences...\n",
      "This may take a few minutes...\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate models on test sentences\n",
    "def evaluate_models(test_sentences, models, model_names):\n",
    "    \"\"\"Evaluate multiple models on test sentences and return results\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sentence in test_sentences:\n",
    "        sentence_results = {'sentence': sentence}\n",
    "        \n",
    "        for model, name in zip(models, model_names):\n",
    "            try:\n",
    "                if hasattr(model, 'sentence_smoothed_log_probability'):\n",
    "                    log_prob = model.sentence_smoothed_log_probability(sentence)\n",
    "                else:\n",
    "                    log_prob = model.sentence_log_probability(sentence)\n",
    "                sentence_results[name] = log_prob\n",
    "            except Exception as e:\n",
    "                sentence_results[name] = float('-inf')\n",
    "        \n",
    "        results.append(sentence_results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Define all models and their names\n",
    "all_models = [\n",
    "    # Original models\n",
    "    unigram_model, bigram_model, trigram_model, quadrigram_model,\n",
    "    # Add-one smoothed models\n",
    "    unigram_add_one, bigram_add_one, trigram_add_one, quadrigram_add_one,\n",
    "    # Add-k smoothed models\n",
    "    unigram_add_k, bigram_add_k, trigram_add_k, quadrigram_add_k,\n",
    "    # Add token type smoothed models\n",
    "    unigram_add_token, bigram_add_token, trigram_add_token, quadrigram_add_token\n",
    "]\n",
    "\n",
    "model_names = [\n",
    "    # Original models\n",
    "    'Unigram', 'Bigram', 'Trigram', 'Quadrigram',\n",
    "    # Add-one smoothed models\n",
    "    'Unigram_Add1', 'Bigram_Add1', 'Trigram_Add1', 'Quadrigram_Add1',\n",
    "    # Add-k smoothed models\n",
    "    'Unigram_AddK', 'Bigram_AddK', 'Trigram_AddK', 'Quadrigram_AddK',\n",
    "    # Add token type smoothed models\n",
    "    'Unigram_AddToken', 'Bigram_AddToken', 'Trigram_AddToken', 'Quadrigram_AddToken'\n",
    "]\n",
    "\n",
    "print(\"Evaluating all models on test sentences...\")\n",
    "print(\"This may take a few minutes...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98b25759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed!\n",
      "Results DataFrame shape: (1000, 17)\n",
      "\n",
      "First few results:\n",
      "                                            sentence     Unigram      Bigram  \\\n",
      "0  रालोसपा के प्रदेश अध्यक्ष भूदेव चौधरी के पाला ... -371.224642 -239.755235   \n",
      "1                                   नए नियम के फायदे  -34.191738  -25.064741   \n",
      "2  अगर राहुल कंवल सवालों का जवाब हमें देते हैं तो... -147.843928  -91.292771   \n",
      "3             शशांक की दो महीने पहले ही शादी हुई है।  -65.330563  -40.877413   \n",
      "4                      किंतु मामले में कुछ नहीं हुआ।  -44.776374  -27.317377   \n",
      "\n",
      "      Trigram  Quadrigram  Unigram_Add1  Bigram_Add1  Trigram_Add1  \\\n",
      "0 -105.535552  -54.829386   -372.390006  -431.561550   -514.437669   \n",
      "1  -16.956102  -12.841139    -34.334650   -43.445464    -48.454023   \n",
      "2  -53.351091  -22.865604   -148.354561  -166.553783   -207.680047   \n",
      "3  -30.945912  -17.420991    -65.581545   -72.999099    -98.262664   \n",
      "4  -22.218029  -15.849293    -44.983329   -49.302828    -64.636086   \n",
      "\n",
      "   Quadrigram_Add1  Unigram_AddK  Bigram_AddK  Trigram_AddK  Quadrigram_AddK  \\\n",
      "0      -552.124632   -371.807795  -406.532759   -488.886922      -529.456693   \n",
      "1       -49.957552    -34.263808   -41.022338    -46.062606       -47.796110   \n",
      "2      -221.430425   -148.099665  -155.615406   -197.577649      -212.676681   \n",
      "3      -108.223452    -65.456801   -67.740522    -93.559134      -104.308458   \n",
      "4       -71.460004    -44.880715   -45.710550    -60.783329       -68.212086   \n",
      "\n",
      "   Unigram_AddToken  Bigram_AddToken  Trigram_AddToken  Quadrigram_AddToken  \n",
      "0       -590.913491      -600.176757       -600.613785          -600.657337  \n",
      "1        -56.118648       -57.754078        -57.754645           -57.754712  \n",
      "2       -239.518862      -242.469268       -242.561909          -242.567918  \n",
      "3       -113.558361      -115.193485       -115.505268          -115.511152  \n",
      "4        -79.150207       -80.831282        -80.856590           -80.857552  \n"
     ]
    }
   ],
   "source": [
    "# Evaluate models on test sentences\n",
    "results = evaluate_models(test_sentences, all_models, model_names)\n",
    "\n",
    "# Convert results to DataFrame for better analysis\n",
    "import pandas as pd\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"Evaluation completed!\")\n",
    "print(f\"Results DataFrame shape: {df_results.shape}\")\n",
    "print(\"\\nFirst few results:\")\n",
    "print(df_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ca1fc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LANGUAGE MODEL PERFORMANCE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Unigram:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -167.0437\n",
      "  Std log probability: 148.3488\n",
      "  Min log probability: -2009.3965\n",
      "  Max log probability: -8.5496\n",
      "\n",
      "Bigram:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -100.7951\n",
      "  Std log probability: 90.5417\n",
      "  Min log probability: -1266.0692\n",
      "  Max log probability: -7.5296\n",
      "\n",
      "Trigram:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -48.0706\n",
      "  Std log probability: 40.0302\n",
      "  Min log probability: -608.9864\n",
      "  Max log probability: -7.5296\n",
      "\n",
      "Quadrigram:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -22.5874\n",
      "  Std log probability: 13.8057\n",
      "  Min log probability: -190.0451\n",
      "  Max log probability: -7.5296\n",
      "\n",
      "Unigram_Add1:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -167.2119\n",
      "  Std log probability: 148.3774\n",
      "  Min log probability: -2014.7825\n",
      "  Max log probability: -8.6133\n",
      "\n",
      "Bigram_Add1:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -189.2490\n",
      "  Std log probability: 169.4323\n",
      "  Min log probability: -2315.6068\n",
      "  Max log probability: -13.4525\n",
      "\n",
      "Trigram_Add1:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -224.5824\n",
      "  Std log probability: 199.9304\n",
      "  Min log probability: -2805.5521\n",
      "  Max log probability: -15.2750\n",
      "\n",
      "Quadrigram_Add1:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -236.2032\n",
      "  Std log probability: 209.9212\n",
      "  Min log probability: -2946.2641\n",
      "  Max log probability: -15.2750\n",
      "\n",
      "Unigram_AddK:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -167.1025\n",
      "  Std log probability: 148.3326\n",
      "  Min log probability: -2012.0203\n",
      "  Max log probability: -8.5817\n",
      "\n",
      "Bigram_AddK:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -178.2214\n",
      "  Std log probability: 159.9065\n",
      "  Min log probability: -2176.1214\n",
      "  Max log probability: -12.8168\n",
      "\n",
      "Trigram_AddK:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -213.8626\n",
      "  Std log probability: 190.6152\n",
      "  Min log probability: -2673.0091\n",
      "  Max log probability: -14.3578\n",
      "\n",
      "Quadrigram_AddK:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -226.5158\n",
      "  Std log probability: 201.5217\n",
      "  Min log probability: -2829.4869\n",
      "  Max log probability: -14.3578\n",
      "\n",
      "Unigram_AddToken:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -256.9936\n",
      "  Std log probability: 223.6348\n",
      "  Min log probability: -3137.8616\n",
      "  Max log probability: -22.1159\n",
      "\n",
      "Bigram_AddToken:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -260.5909\n",
      "  Std log probability: 226.3436\n",
      "  Min log probability: -3175.5366\n",
      "  Max log probability: -22.9769\n",
      "\n",
      "Trigram_AddToken:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -260.7628\n",
      "  Std log probability: 226.4104\n",
      "  Min log probability: -3176.5293\n",
      "  Max log probability: -23.1008\n",
      "\n",
      "Quadrigram_AddToken:\n",
      "  Valid predictions: 1000/1000 (100.0%)\n",
      "  Mean log probability: -260.7710\n",
      "  Std log probability: 226.4162\n",
      "  Min log probability: -3176.5528\n",
      "  Max log probability: -23.1008\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display statistics for each model\n",
    "print(\"=\"*80)\n",
    "print(\"LANGUAGE MODEL PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Exclude 'sentence' column for statistical analysis\n",
    "model_columns = [col for col in df_results.columns if col != 'sentence']\n",
    "\n",
    "for col in model_columns:\n",
    "    valid_scores = df_results[col][df_results[col] != float('-inf')]\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Valid predictions: {len(valid_scores)}/{len(df_results)} ({len(valid_scores)/len(df_results)*100:.1f}%)\")\n",
    "    \n",
    "    if len(valid_scores) > 0:\n",
    "        print(f\"  Mean log probability: {valid_scores.mean():.4f}\")\n",
    "        print(f\"  Std log probability: {valid_scores.std():.4f}\")\n",
    "        print(f\"  Min log probability: {valid_scores.min():.4f}\")\n",
    "        print(f\"  Max log probability: {valid_scores.max():.4f}\")\n",
    "    else:\n",
    "        print(\"  No valid predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a541032f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARISON: ORIGINAL vs SMOOTHED MODELS\n",
      "================================================================================\n",
      "\n",
      "PERCENTAGE OF VALID PREDICTIONS:\n",
      "--------------------------------------------------\n",
      "Unigram:\n",
      "  Original:     1000/1000 (100.0%)\n",
      "  Add-One:      1000/1000 (100.0%)\n",
      "  Add-K:        1000/1000 (100.0%)\n",
      "  Add-Token:    1000/1000 (100.0%)\n",
      "\n",
      "Bigram:\n",
      "  Original:     1000/1000 (100.0%)\n",
      "  Add-One:      1000/1000 (100.0%)\n",
      "  Add-K:        1000/1000 (100.0%)\n",
      "  Add-Token:    1000/1000 (100.0%)\n",
      "\n",
      "Trigram:\n",
      "  Original:     1000/1000 (100.0%)\n",
      "  Add-One:      1000/1000 (100.0%)\n",
      "  Add-K:        1000/1000 (100.0%)\n",
      "  Add-Token:    1000/1000 (100.0%)\n",
      "\n",
      "Quadrigram:\n",
      "  Original:     1000/1000 (100.0%)\n",
      "  Add-One:      1000/1000 (100.0%)\n",
      "  Add-K:        1000/1000 (100.0%)\n",
      "  Add-Token:    1000/1000 (100.0%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare original models vs smoothed models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: ORIGINAL vs SMOOTHED MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Group models by type\n",
    "original_models = ['Unigram', 'Bigram', 'Trigram', 'Quadrigram']\n",
    "add_one_models = ['Unigram_Add1', 'Bigram_Add1', 'Trigram_Add1', 'Quadrigram_Add1']\n",
    "add_k_models = ['Unigram_AddK', 'Bigram_AddK', 'Trigram_AddK', 'Quadrigram_AddK']\n",
    "add_token_models = ['Unigram_AddToken', 'Bigram_AddToken', 'Trigram_AddToken', 'Quadrigram_AddToken']\n",
    "\n",
    "print(\"\\nPERCENTAGE OF VALID PREDICTIONS:\")\n",
    "print(\"-\" * 50)\n",
    "for i, ngram_type in enumerate(['Unigram', 'Bigram', 'Trigram', 'Quadrigram']):\n",
    "    orig_valid = len(df_results[original_models[i]][df_results[original_models[i]] != float('-inf')])\n",
    "    add1_valid = len(df_results[add_one_models[i]][df_results[add_one_models[i]] != float('-inf')])\n",
    "    addk_valid = len(df_results[add_k_models[i]][df_results[add_k_models[i]] != float('-inf')])\n",
    "    token_valid = len(df_results[add_token_models[i]][df_results[add_token_models[i]] != float('-inf')])\n",
    "    \n",
    "    total = len(df_results)\n",
    "    \n",
    "    print(f\"{ngram_type}:\")\n",
    "    print(f\"  Original:     {orig_valid}/{total} ({orig_valid/total*100:.1f}%)\")\n",
    "    print(f\"  Add-One:      {add1_valid}/{total} ({add1_valid/total*100:.1f}%)\")\n",
    "    print(f\"  Add-K:        {addk_valid}/{total} ({addk_valid/total*100:.1f}%)\")\n",
    "    print(f\"  Add-Token:    {token_valid}/{total} ({token_valid/total*100:.1f}%)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "927c3b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAMPLE SENTENCE PROBABILITY CALCULATIONS\n",
      "================================================================================\n",
      "\n",
      "Sentence 1: रालोसपा के प्रदेश अध्यक्ष भूदेव चौधरी के पाला बदलकर राजद में सोमवार को शामिल होने के बारे में पूछे जाने पर कुशवाहा ने कहा कि मैंने दूसरे किनारे तक पहुंचने के इरादे से समुद्र में अपनी नाव डाली है पर बीच में छोड़कर जो जाना चाहते हैं तो उनका स्वागत है।\n",
      "------------------------------------------------------------\n",
      "Model Type        | Add-One      | Add-K        | Add-Token\n",
      "------------------------------------------------------------\n",
      "Unigram        | -372.3900    | -371.8078    | -590.9135\n",
      "Bigram         | -431.5615    | -406.5328    | -600.1768\n",
      "Trigram        | -514.4377    | -488.8869    | -600.6138\n",
      "Quadrigram     | -552.1246    | -529.4567    | -600.6573\n",
      "\n",
      "\n",
      "Sentence 2: नए नियम के फायदे\n",
      "------------------------------------------------------------\n",
      "Model Type        | Add-One      | Add-K        | Add-Token\n",
      "------------------------------------------------------------\n",
      "Unigram        | -34.3346     | -34.2638     | -56.1186\n",
      "Bigram         | -43.4455     | -41.0223     | -57.7541\n",
      "Trigram        | -48.4540     | -46.0626     | -57.7546\n",
      "Quadrigram     | -49.9576     | -47.7961     | -57.7547\n",
      "\n",
      "\n",
      "Sentence 3: अगर राहुल कंवल सवालों का जवाब हमें देते हैं तो इस खबर को उनके पक्ष के साथ अपडेट किया जाएगा।\n",
      "------------------------------------------------------------\n",
      "Model Type        | Add-One      | Add-K        | Add-Token\n",
      "------------------------------------------------------------\n",
      "Unigram        | -148.3546    | -148.0997    | -239.5189\n",
      "Bigram         | -166.5538    | -155.6154    | -242.4693\n",
      "Trigram        | -207.6800    | -197.5776    | -242.5619\n",
      "Quadrigram     | -221.4304    | -212.6767    | -242.5679\n",
      "\n",
      "\n",
      "Sentence 4: शशांक की दो महीने पहले ही शादी हुई है।\n",
      "------------------------------------------------------------\n",
      "Model Type        | Add-One      | Add-K        | Add-Token\n",
      "------------------------------------------------------------\n",
      "Unigram        | -65.5815     | -65.4568     | -113.5584\n",
      "Bigram         | -72.9991     | -67.7405     | -115.1935\n",
      "Trigram        | -98.2627     | -93.5591     | -115.5053\n",
      "Quadrigram     | -108.2235    | -104.3085    | -115.5112\n",
      "\n",
      "\n",
      "Sentence 5: किंतु मामले में कुछ नहीं हुआ।\n",
      "------------------------------------------------------------\n",
      "Model Type        | Add-One      | Add-K        | Add-Token\n",
      "------------------------------------------------------------\n",
      "Unigram        | -44.9833     | -44.8807     | -79.1502\n",
      "Bigram         | -49.3028     | -45.7106     | -80.8313\n",
      "Trigram        | -64.6361     | -60.7833     | -80.8566\n",
      "Quadrigram     | -71.4600     | -68.2121     | -80.8576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show examples of sentence probabilities\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE SENTENCE PROBABILITY CALCULATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show results for first 5 test sentences\n",
    "sample_results = df_results.head(5)\n",
    "\n",
    "for idx, row in sample_results.iterrows():\n",
    "    print(f\"\\nSentence {idx+1}: {row['sentence']}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Show results for each smoothing technique across all n-grams\n",
    "    print(\"Model Type        | Add-One      | Add-K        | Add-Token\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, ngram in enumerate(['Unigram', 'Bigram', 'Trigram', 'Quadrigram']):\n",
    "        add_one_score = row[f'{ngram}_Add1']\n",
    "        add_k_score = row[f'{ngram}_AddK']\n",
    "        add_token_score = row[f'{ngram}_AddToken']\n",
    "        \n",
    "        add_one_str = f\"{add_one_score:.4f}\" if add_one_score != float('-inf') else \"-inf\"\n",
    "        add_k_str = f\"{add_k_score:.4f}\" if add_k_score != float('-inf') else \"-inf\"\n",
    "        add_token_str = f\"{add_token_score:.4f}\" if add_token_score != float('-inf') else \"-inf\"\n",
    "        \n",
    "        print(f\"{ngram:<14} | {add_one_str:<12} | {add_k_str:<12} | {add_token_str}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b77993b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to language_model_results.csv\n",
      "\n",
      "================================================================================\n",
      "IMPLEMENTATION SUMMARY\n",
      "================================================================================\n",
      "✓ Built 4 Language Models:\n",
      "  - Unigram Model\n",
      "  - Bigram Model\n",
      "  - Trigram Model\n",
      "  - Quadrigram Model\n",
      "\n",
      "✓ Implemented 3 Smoothing Techniques:\n",
      "  - Add-One Smoothing (Laplace)\n",
      "  - Add-K Smoothing (k=0.5)\n",
      "  - Add Token Type Smoothing\n",
      "\n",
      "✓ Evaluated on 1000 random sentences from the dataset\n",
      "✓ Calculated log probabilities to avoid numerical underflow\n",
      "✓ Applied smoothing to all 4 n-gram models\n",
      "\n",
      "Total dataset size: 141536 sentences\n",
      "Vocabulary size: 103893 unique tokens\n",
      "Test set size: 1000 sentences\n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV for further analysis\n",
    "output_file = 'language_model_results.csv'\n",
    "df_results.to_csv(output_file, index=False, encoding='utf-8')\n",
    "print(f\"Results saved to {output_file}\")\n",
    "\n",
    "# Summary of the implementation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IMPLEMENTATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"✓ Built 4 Language Models:\")\n",
    "print(\"  - Unigram Model\")\n",
    "print(\"  - Bigram Model\") \n",
    "print(\"  - Trigram Model\")\n",
    "print(\"  - Quadrigram Model\")\n",
    "print()\n",
    "print(\"✓ Implemented 3 Smoothing Techniques:\")\n",
    "print(\"  - Add-One Smoothing (Laplace)\")\n",
    "print(\"  - Add-K Smoothing (k=0.5)\")\n",
    "print(\"  - Add Token Type Smoothing\")\n",
    "print()\n",
    "print(\"✓ Evaluated on 1000 random sentences from the dataset\")\n",
    "print(\"✓ Calculated log probabilities to avoid numerical underflow\")\n",
    "print(\"✓ Applied smoothing to all 4 n-gram models\")\n",
    "print()\n",
    "print(f\"Total dataset size: {len(sentences)} sentences\")\n",
    "print(f\"Vocabulary size: {len(unigram_model.vocabulary)} unique tokens\")\n",
    "print(f\"Test set size: {len(test_sentences)} sentences\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
